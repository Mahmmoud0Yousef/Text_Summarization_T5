import streamlit as st
from transformers import T5ForConditionalGeneration, T5Tokenizer
import re
import string
import time
import pandas as pd
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ù€ tokenizer
@st.cache_resource
def load_model():
    model = T5ForConditionalGeneration.from_pretrained("models/t5_summarizer_model")
    tokenizer = T5Tokenizer.from_pretrained("models/t5_summarizer_model")
    return model, tokenizer

model, tokenizer = load_model()

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ stopwords
stop_word = set(stopwords.words("english"))
negation_words = {
    "not", "no", "never", "none", "nobody", "nothing", "neither", "nowhere",
    "hasn't", "haven't", "hadn't", "doesn't", "don't", "didn't",
    "won't", "wouldn't", "can't", "couldn't", "isn't", "aren't", "wasn't", "weren't",
    "without", "nor"
}
filtered_stopwords = stop_word - negation_words

# ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
def Preprocessing_text(text):
    text = text.lower()
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r"http\S+", "", text)
    text = re.sub(r"[^\w\s]", "", text)
    text = re.sub(r'\s+', ' ', text).strip()
    words = text.split()
    filtered = [word for word in words if word not in filtered_stopwords]
    return " ".join(filtered)

# Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ„Ø®ÙŠØµ
def summarize_dialogue(dialogue, max_len, min_len):
    dialogue = Preprocessing_text(dialogue)
    inputs = tokenizer(dialogue, return_tensors="pt", truncation=True, padding="max_length", max_length=512)
    outputs = model.generate(
        inputs["input_ids"],
        max_length=max_len,
        min_length=min_len,
        num_beams=4,
        length_penalty=2.0,
        early_stopping=True
    )
    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return summary

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="T5 Summarizer", layout="wide")
st.title("ğŸ“ Dialogue to Summary - T5 Summarizer")

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
with st.sidebar:
    st.header("âš™ï¸ Summarization Settings")
    max_len = st.slider("Maximum summary length", 50, 300, 150, step=10)
    min_len = st.slider("Minimum summary length", 10, 100, 30, step=5)

# Ø±ÙØ¹ Ù…Ù„Ù
st.markdown("### ğŸ“ Upload a text file (one dialogue per line):")
uploaded_file = st.file_uploader("Choose a TXT file", type=["txt"])

if uploaded_file:
    raw_lines = uploaded_file.read().decode("utf-8").splitlines()
    cleaned_lines = []
    summaries = []

    with st.spinner("â³ Summarizing dialogues..."):
        for line in raw_lines:
            if line.strip():
                cleaned_lines.append(line)
                summary = summarize_dialogue(line, max_len=max_len, min_len=min_len)
                summaries.append(summary)

    if cleaned_lines:
        df = pd.DataFrame({"Dialogue": cleaned_lines, "Summary": summaries})
        st.success(f"âœ… {len(df)} dialogues summarized.")
        st.dataframe(df, use_container_width=True)

        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button("ğŸ“¥ Download CSV", csv, "bulk_summaries.csv", "text/csv")
    else:
        st.warning("âš ï¸ No valid dialogues found in the file.")

st.divider()

# Ø¥Ø¯Ø®Ø§Ù„ ÙŠØ¯ÙˆÙŠ
st.markdown("### ğŸ§¾ Paste a single dialogue to summarize:")
dialogue = st.text_area("Enter full conversation", height=250)

if st.button("ğŸ” Summarize"):
    if dialogue.strip():
        start_time = time.time()
        with st.spinner("Summarizing..."):
            summary = summarize_dialogue(dialogue, max_len=max_len, min_len=min_len)
        elapsed_time = time.time() - start_time

        st.success("âœ… Summarization complete!")
        st.markdown("### ğŸ“„ Summary:")
        st.text_area("Result", summary, height=150)
        st.info(f"â±ï¸ Time taken: {elapsed_time:.2f} seconds")

        df = pd.DataFrame([{"Dialogue": dialogue, "Summary": summary}])
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button("ğŸ“¥ Download CSV", csv, "summary.csv", "text/csv")
    else:
        st.warning("âš ï¸ Please enter a conversation.")
